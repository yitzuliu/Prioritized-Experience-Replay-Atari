# IceHockey (ALE/IceHockey-v5)

## ğŸ“¦ Environment Summary

- **Environment Name**: `ALE/IceHockey-v5`
- **Game Time Limit**: 3 minutes
- **Goal**: Score as many goals as possible by shooting the puck into the opponent's goal
- **Key Feature**: 32 different shot angles toward the opponent's goal; players can also pass the puck by bouncing it off the rink's sides

*IceHockey æ˜¯ä¸€å€‹ Atari ç’°å¢ƒï¼Œå»ºè­°å…ˆé–±è®€ [Atari Environments ç¸½è¦½é é¢](https://gym.openai.com/envs/#atari) ä»¥äº†è§£é€šç”¨è³‡è¨Šã€‚*

---

## ğŸ® Action Space

- **Type**: `Discrete(18)`
- **Description**: All possible Atari 2600 actions are enabled by default, regardless of version or `full_action_space` setting

### Our Implementation

In our implementation, we utilize all 18 possible actions and select them using an `Îµ-greedy` strategy. The exploration rate (Îµ) gradually decreases from 1.0 to 0.1 during training, transitioning the agent from exploration to exploitation of learned strategies.

*åœ¨æˆ‘å€‘çš„å¯¦ç¾ä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨ 18 å€‹å¯èƒ½çš„å‹•ä½œï¼Œä¸¦é€šé `Îµ-greedy` ç­–ç•¥é¸æ“‡å‹•ä½œã€‚éš¨è‘—è¨“ç·´é€²è¡Œï¼Œæ¢ç´¢ç‡ (Îµ) å¾ 1.0 é€æ¼¸æ¸›å°‘åˆ° 0.1ï¼Œä½¿æ™ºèƒ½é«”å¾åˆæœŸçš„æ¢ç´¢è½‰å‘å¾ŒæœŸçš„åˆ©ç”¨å­¸ç¿’åˆ°çš„ç­–ç•¥ã€‚*

---

## ğŸ‘€ Observation Space

- **Default**: `Box((210, 160, 3), dtype=uint8)` (RGB image)
- **Alternatives**:
  - **RAM**: `Box((128,), dtype=uint8)`
  - **Grayscale Image**: `Box((250, 160), dtype=uint8)`

### Our Preprocessing

In our implementation, we apply the following preprocessing steps:
- Convert to grayscale to reduce input dimensionality
- Resize to 84Ã—84 pixels to standardize input size
- Stack 4 consecutive frames to provide temporal information
- Normalize pixel values to [0, 1] range
- Use frame skipping technique, making a decision every 4 frames

The final processed observation space is `(4, 84, 84)`, representing 4 stacked grayscale frames of 84Ã—84 pixels.

*åœ¨æˆ‘å€‘çš„å¯¦ç¾ä¸­ï¼Œæˆ‘å€‘æ‡‰ç”¨äº†ä»¥ä¸‹é è™•ç†æ­¥é©Ÿ:*
*- è½‰æ›ç‚ºç°éšåœ–åƒä»¥æ¸›å°‘è¼¸å…¥ç¶­åº¦*
*- ç¸®æ”¾è‡³ 84Ã—84 åƒç´ ä»¥æ¨™æº–åŒ–è¼¸å…¥å¤§å°*
*- å †ç–Š 4 å€‹é€£çºŒå¹€ä»¥æä¾›æ™‚é–“åºåˆ—ä¿¡æ¯*
*- æ¨™æº–åŒ–åƒç´ å€¼åˆ° [0, 1] ç¯„åœ*
*- ä½¿ç”¨è·³å¹€ï¼ˆframe skippingï¼‰æŠ€è¡“ï¼Œæ¯ 4 å¹€é€²è¡Œä¸€æ¬¡æ±ºç­–*

*æœ€çµ‚è™•ç†å¾Œçš„è§€å¯Ÿç©ºé–“ç‚º `(4, 84, 84)`ï¼Œè¡¨ç¤º 4 å€‹å †ç–Šçš„ 84Ã—84 ç°éšå¹€ã€‚*

---

## ğŸ… Rewards

- Points are awarded by scoring goals.
- There is no upper limit to the score other than the 3-minute game timer.

### Reward Processing

In our implementation, we process rewards as follows:
- Clip rewards to {+1, 0, -1} by taking the sign of the original reward
- This processing helps stabilize training and prevents value function divergence due to large rewards

*åœ¨æˆ‘å€‘çš„å¯¦ç¾ä¸­ï¼Œæˆ‘å€‘å°çå‹µé€²è¡Œäº†ä»¥ä¸‹è™•ç†:*
*- çå‹µè£å‰ªåˆ° {+1, 0, -1} ç¯„åœï¼Œé€šéå–åŸå§‹çå‹µçš„ç¬¦è™Ÿä¾†å¯¦ç¾*
*- é€™ç¨®è™•ç†æœ‰åŠ©æ–¼ç©©å®šè¨“ç·´éç¨‹ï¼Œé˜²æ­¢å¤§çå‹µå°è‡´çš„å€¼å‡½æ•¸ç™¼æ•£*

---

## âš™ï¸ Environment Configuration

- **Import Example**:
  ```python
  import gym
  env = gym.make("ALE/IceHockey-v5")
  ```

### Wrapper Usage

We use the following environment wrappers to enhance learning:
- `NoopResetEnv`: Executes random number of no-ops on reset to increase initial state diversity
- `MaxAndSkipEnv`: Takes max of consecutive frames to deal with flickering
- `ResizeFrame`: Resizes frames and converts to grayscale
- `NormalizedFrame`: Normalizes pixel values
- `FrameStack`: Stacks consecutive frames to provide temporal information
- `ClipRewardEnv`: Clips rewards

The complete environment creation code can be found in the `make_atari_env()` function in `src/env_wrappers.py`.

*æˆ‘å€‘ä½¿ç”¨äº†ä»¥ä¸‹ç’°å¢ƒåŒ…è£å™¨ä¾†å¢å¼·å­¸ç¿’æ•ˆæœ:*
*- `NoopResetEnv`: åœ¨é‡ç½®æ™‚åŸ·è¡Œéš¨æ©Ÿæ•¸é‡çš„ç„¡æ“ä½œï¼Œå¢åŠ åˆå§‹ç‹€æ…‹çš„å¤šæ¨£æ€§*
*- `MaxAndSkipEnv`: è™•ç†é€£çºŒå¹€ä¹‹é–“çš„æœ€å¤§å€¼ï¼Œè§£æ±ºé–ƒçˆå•é¡Œ*
*- `ResizeFrame`: èª¿æ•´å¹€å¤§å°ä¸¦è½‰æ›ç‚ºç°éš*
*- `NormalizedFrame`: æ¨™æº–åŒ–åƒç´ å€¼*
*- `FrameStack`: å †ç–Šé€£çºŒå¹€ä»¥æä¾›æ™‚é–“åºåˆ—ä¿¡æ¯*
*- `ClipRewardEnv`: è£å‰ªçå‹µ*

*å®Œæ•´çš„ç’°å¢ƒå‰µå»ºä»£ç¢¼å¯åœ¨ `src/env_wrappers.py` ä¸­çš„ `make_atari_env()` å‡½æ•¸ä¸­æ‰¾åˆ°ã€‚*
